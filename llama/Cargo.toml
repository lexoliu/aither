[package]
name = "aither-llama"
version = "0.1.0"
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
rust-version.workspace = true
description = "Local llama.cpp provider integration for aither"
readme = "../README.md"
keywords = ["ai", "llm", "llama", "llama.cpp", "embedding"]
categories = ["api-bindings"]

[dependencies]
aither-core.workspace = true
async-stream = "0.3"
futures-core = { version = "0.3", default-features = false }
futures-lite = "2.6"
encoding_rs = "0.8"
llama-cpp-2 = { version = "0.1.133", features = ["sampler"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "2"
tracing.workspace = true

[lints]
workspace = true
